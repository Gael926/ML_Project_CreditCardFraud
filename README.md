# D√©tection de fraudes par carte bancaire ‚Äî Notebook & Mod√®les


Ce README documente le notebook **fraud_detection.ipynb** : de l'exploration des donn√©es jusqu'√† l'entra√Ænement et l'√©valuation de mod√®les de classification pour la d√©tection de fraudes.

- **Jeu de donn√©es** : `creditcard.csv` (transactions anonymis√©es par PCA, cible `Class`).
- **Taille** : 284807 lignes √ó 31 colonnes.
- **D√©s√©quilibre** : classe 1 (fraude) ‚âà 0.173% (492 cas) vs classe 0 (l√©gitime) ‚âà 99.827% (284315 cas).

## 1) Exploration rapide (EDA)
- Aucune valeur manquante d√©tect√©e selon l'aper√ßu initial.
- **Montant** tr√®s asym√©trique (skewness ‚âà **16.978**). Normal.

**Distribution de la cible**

![Distribution de la classe](assets/class_distribution_1670778c.png)


## 2) Pr√©traitement

- **Standardisation de `Amount`** uniquement (`StandardScaler`) ; les variables `V1..V28` sont d√©j√† ¬´ normalis√©es ¬ª (PCA).
- **D√©coupage**: `train_test_split(..., stratify=y)` pour conserver les proportions.
- **Pipeline scikit-learn**: `ColumnTransformer` + mod√®le, afin d'assurer une inf√©rence reproductible.

## 3) Mod√®les & r√©glages

- **R√©gression Logistique** : `class_weight="balanced"`, grille (`C`, `penalty`, `solver`), `scoring="roc_auc"`.
- **Random Forest** : baseline `class_weight="balanced"`, puis `RandomizedSearchCV` (n_estimators, max_depth, min_samples_leaf, max_features, max_samples), `scoring="roc_auc"`.
- **XGBoost** : `RandomizedSearchCV` puis `GridSearchCV` ciblant **`average_precision` (PR-AUC)**, puis entra√Ænement final avec **early stopping** sur un jeu de validation (m√©trique `aucpr`).
**Courbe de validation (RandomForest / max_depth ‚Üí Recall)**

![Validation Curve RF](assets/rf_validation_curve_c04977ff.png)


## 4) √âvaluation & r√©sultats

**Comparatif sur le jeu de test**

| Mod√®le | ROC-AUC | PR-AUC | Rappel | Pr√©cision | F1 |
|---|---:|---:|---:|---:|---:|
| Logistic Regression | 0.9724 | 0.6929 | 0.8862 | 0.0637 | 0.1188 |
| Random Forest (tuned) | 0.9738 | 0.8321 | 0.7724 | 0.9048 | 0.8333 |
| Logistic Regression | 0.9724 | 0.6929 | 0.8862 | 0.0637 | 0.1188 |
| Random Forest (tuned) | 0.9738 | 0.8321 | 0.7724 | 0.9048 | 0.8333 |
| XGBoost (baseline) | 0.9831 | 0.8608 | 0.8374 | 0.8306 | 0.8340 |

| Mod√®le | ROC-AUC | PR-AUC | Rappel | Pr√©cision | F1 |
|---|---:|---:|---:|---:|---:|
| Logistic Regression | 0.9724 | 0.6929 | 0.8862 | 0.0637 | 0.1188 |
| Random Forest (tuned) | 0.9738 | 0.8321 | 0.7724 | 0.9048 | 0.8333 |
| Logistic Regression | 0.9724 | 0.6929 | 0.8862 | 0.0637 | 0.1188 |
| Random Forest (tuned) | 0.9738 | 0.8321 | 0.7724 | 0.9048 | 0.8333 |
| XGBoost (baseline) | 0.9831 | 0.8608 | 0.8374 | 0.8306 | 0.8340 |

**R√©gression Logistique ‚Äî diagnostics**

- Matrice de confusion :

![CM LogReg](assets/confusion_matrix_logreg_9bf69f09.png)

**XGBoost (mod√®le final)**

- **It√©ration optimale** (early stopping): **954**
- **Meilleure PR-AUC (val.)**: **0.8397**
- **Seuil optimis√©**: **0.855**
- **√Ä ce seuil** ‚Üí Pr√©cision **0.967**, Rappel **0.797**, F1 **0.874**

_Remarque_: sur donn√©es tr√®s d√©s√©quilibr√©es, **PR-AUC** est plus informative que ROC-AUC.


## 5) Export du mod√®le & inf√©rence

Le pipeline final est s√©rialis√© avec `joblib` : `../models/xgb_final_model.pkl`.

**Charger et pr√©dire**

```python
import joblib
import pandas as pd

model = joblib.load("models/xgb_final_model.pkl")  # chemin relatif depuis la racine du projet
X_new = pd.DataFrame([...])  # m√™mes colonnes que l'entra√Ænement
probas = model.predict_proba(X_new)[:, 1]
preds = (probas >= 0.855).astype(int)  # seuil issu du notebook (√† ajuster selon co√ªt m√©tier)
```

## 6) Reproductibilit√©

- Fixation des graines (`random_state=42`).
- Pipelines scikit-learn garantissant le m√™me pr√©traitement en entra√Ænement et inf√©rence.
- **√Ä pr√©voir dans le repo** (recommand√©) :
  - `requirements.txt` ou `environment.yml`,
  - dossier `data/` (non versionn√©) avec `creditcard.csv`,
  - dossiers `images/`, `models/`, `notebooks/`, `reports/`,
  - script `train.py` (optionnel) pour rejouer l‚Äôentra√Ænement hors notebook.

## 7) Limites & pistes d'am√©lioration (80/20)

- **Seuil d√©cisionnel**: optimiser vs. **co√ªts** (faux positifs vs. vrais positifs). Fournir une courbe pr√©cision‚Äìrappel + table `Precision@K`.
- **Explicabilit√© rapide**: importance des variables (XGBoost `feature_importances_`), SHAP (optionnel).
- **Calibration**: v√©rifier la calibration des probabilit√©s (ex. `CalibratedClassifierCV`).
- **Drift**: pr√©voir suivi des d√©rives (statistiques de base & taux de fraude au fil du temps).

## 8) Comment rejouer le notebook

1. Placer `creditcard.csv` dans `data/` et ajuster le chemin dans la cellule de chargement.
2. Installer les d√©pendances minimales :
   ```bash
   pip install -U pandas scikit-learn xgboost matplotlib seaborn joblib
   ```
3. Ex√©cuter toutes les cellules. Les figures cl√©s sont sauvegard√©es et √©galement export√©es ci-dessus.

## 9) √Ä faire / Propositions

- [ ] Exporter syst√©matiquement **toutes les figures** en `.png` (DPI ‚â• 200) vers `images/` (tu as d√©j√† des `plt.savefig(...)` pour la LogReg üëç).
- [ ] G√©n√©rer automatiquement un **rapport** (ex. `reports/metrics.json` + `reports/figures.md`) en fin de notebook.
- [ ] Ajouter `requirements.txt` (je peux te le d√©duire depuis le notebook si tu veux).
- [ ] Ajouter un **script d'inf√©rence** minimal (`predict.py`) qui charge le mod√®le et applique le seuil.